{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Import Package"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load & Prepare Dataset"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Download IMDB Reviews Dataset in Plain Text (Word)"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"imdb_reviews_word_ds = tfds.load(\"imdb_reviews\", as_supervised=True)\nimdb_reviews_word_ds_training = list(imdb_reviews_word_ds[\"train\"])\nimdb_reviews_word_ds_validation = list(imdb_reviews_word_ds[\"test\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Prepare Training & Validation Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_word_ds = []\ny_train_word_ds = []\n\nfor text, label in imdb_reviews_word_ds_training:\n    \n    x_train_word_ds.append(text.numpy().decode(\"utf-8\"))\n    y_train_word_ds.append(label.numpy())\n    \n\nx_validation_word_ds = []\ny_validation_word_ds = []\n\nfor text, label in imdb_reviews_word_ds_validation:\n    \n    x_validation_word_ds.append(text.numpy().decode(\"utf-8\"))\n    y_validation_word_ds.append(label.numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Tokenize Plain Text"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = keras.preprocessing.text.Tokenizer(num_words=12000, oov_token=\"<OOV>\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.fit_on_texts(texts=x_train_word_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"tokenizer.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_word_ds = tokenizer.texts_to_sequences(texts=x_train_word_ds)\nx_validation_word_ds = tokenizer.texts_to_sequences(texts=x_validation_word_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Pad the Sequences"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_word_ds = keras.preprocessing.sequence.pad_sequences(sequences=x_train_word_ds,\n                                                             maxlen=128,\n                                                             padding=\"post\",\n                                                             truncating=\"post\")\n\nx_validation_word_ds = keras.preprocessing.sequence.pad_sequences(sequences=x_validation_word_ds,\n                                                                  maxlen=128,\n                                                                  padding=\"post\",\n                                                                  truncating=\"post\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Have a Look on Prepared Dataset"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# word dataset for training\ntemp_dict = {\"Text (Word)\": list(x_train_word_ds),\n             \"Label (int)\": y_train_word_ds}\n\npd.DataFrame.from_dict(temp_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# word dataset for validation\ntemp_dict = {\"Text (Word)\": list(x_validation_word_ds),\n             \"Label (int)\": y_validation_word_ds}\n\npd.DataFrame.from_dict(temp_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Covert Prepared Dataset to Numpy Array"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"x_train_word_ds = np.array(x_train_word_ds)\ny_train_word_ds = np.array(y_train_word_ds)\nprint(\"Type of word dataset for training (Text): \", type(x_train_word_ds))\nprint(\"Type of word dataset for training (Label): \", type(y_train_word_ds))\n\nprint()\n\nx_validation_word_ds = np.array(x_validation_word_ds)\ny_validation_word_ds = np.array(y_validation_word_ds)\nprint(\"Type of word dataset for validation (Text): \", type(x_validation_word_ds))\nprint(\"Type of word dataset for validation (Label): \", type(y_validation_word_ds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Shape of Training & Validation Dataset"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print(\"Shape of word dataset for training (Text): \", x_train_word_ds.shape)\nprint(\"Shape of word dataset for training (Label): \", y_train_word_ds.shape)\nprint(\"Shape of word dataset for validation (Text): \", x_validation_word_ds.shape)\nprint(\"Shape of word dataset for validation (Label): \", y_validation_word_ds.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Download IMDB Reviews Dataset in Subword"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"imdb_reviews_subword_ds, info = tfds.load(\"imdb_reviews/subwords8k\", as_supervised=True, with_info=True)\nimdb_reviews_subword_ds_training = list(imdb_reviews_subword_ds[\"train\"])\nimdb_reviews_subword_ds_validation = list(imdb_reviews_subword_ds[\"test\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Prepare Training & Validation Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_subword_ds = []\ny_train_subword_ds = []\n\nfor text, label in imdb_reviews_subword_ds_training:\n    \n    x_train_subword_ds.append(text.numpy())\n    y_train_subword_ds.append(label.numpy())\n    \n\nx_validation_subword_ds = []\ny_validation_subword_ds = []\n\nfor text, label in imdb_reviews_subword_ds_validation:\n    \n    x_validation_subword_ds.append(text.numpy())\n    y_validation_subword_ds.append(label.numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Pad the Sequences"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_subword_ds = keras.preprocessing.sequence.pad_sequences(sequences=x_train_subword_ds,\n                                                                maxlen=200,\n                                                                padding=\"post\",\n                                                                truncating=\"post\")\n\nx_validation_subword_ds = keras.preprocessing.sequence.pad_sequences(sequences=x_validation_subword_ds,\n                                                                     maxlen=200,\n                                                                     padding=\"post\",\n                                                                     truncating=\"post\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Have a Look on Prepared Dataset"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# subword dataset for training\ntemp_dict = {\"Text (Subword)\": list(x_train_subword_ds),\n             \"Label (int)\": y_train_subword_ds}\n\npd.DataFrame.from_dict(temp_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# subword dataset for validation\ntemp_dict = {\"Text (Subword)\": list(x_validation_subword_ds),\n             \"Label (int)\": y_validation_subword_ds}\n\npd.DataFrame.from_dict(temp_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Covert Prepared Dataset to Numpy Array"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"x_train_subword_ds = np.array(x_train_subword_ds)\ny_train_subword_ds = np.array(y_train_subword_ds)\nprint(\"Type of subword dataset for training (Text): \", type(x_train_subword_ds))\nprint(\"Type of subword dataset for training (Label): \", type(y_train_subword_ds))\n\nprint()\n\nx_validation_subword_ds = np.array(x_validation_subword_ds)\ny_validation_subword_ds = np.array(y_validation_subword_ds)\nprint(\"Type of subword dataset for validation (Text): \", type(x_validation_subword_ds))\nprint(\"Type of subword dataset for validation (Label): \", type(y_validation_subword_ds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Shape of Training & Validation Dataset"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print(\"Shape of subword dataset for training (Text): \", x_train_subword_ds.shape)\nprint(\"Shape of subword dataset for training (Label): \", y_train_subword_ds.shape)\nprint(\"Shape of subword dataset for validation (Text): \", x_validation_subword_ds.shape)\nprint(\"Shape of subword dataset for validation (Label): \", y_validation_subword_ds.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Model"},{"metadata":{},"cell_type":"markdown","source":"### Model for Word Dataset"},{"metadata":{},"cell_type":"markdown","source":"### => Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_word = keras.models.Sequential()\nmodel_word.add(keras.layers.Embedding(input_dim=12000, output_dim=32, input_length=128))\nmodel_word.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=True)))\nmodel_word.add(keras.layers.Bidirectional(keras.layers.LSTM(units=64)))\nmodel_word.add(keras.layers.Dense(units=16, activation=\"relu\"))\nmodel_word.add(keras.layers.Dense(units=1, activation=\"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_word.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Compilation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_word.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomCallback(keras.callbacks.Callback):\n    \n    def on_epoch_end(self, epochs, logs):\n        if logs[\"acc\"] >= 0.99:\n            self.model.stop_training = True\n\nmy_callback = CustomCallback()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model for Subword Dataset"},{"metadata":{},"cell_type":"markdown","source":"### => Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_subword = keras.models.Sequential()\nmodel_subword.add(keras.layers.Embedding(input_dim=info.features[\"text\"].encoder.vocab_size, output_dim=32, input_length=200))\nmodel_subword.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=True)))\nmodel_subword.add(keras.layers.Bidirectional(keras.layers.LSTM(units=64)))\nmodel_subword.add(keras.layers.Dense(units=16, activation=\"relu\"))\nmodel_subword.add(keras.layers.Dense(units=1, activation=\"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_subword.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Compilation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_subword.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### => Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Model"},{"metadata":{},"cell_type":"markdown","source":"### Train Model for Word Dataset"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"history_word = model_word.fit(x=x_train_word_ds,\n               y=y_train_word_ds,\n               batch_size=32,\n               epochs=50,\n               callbacks=my_callback,\n               validation_data=(x_validation_word_ds, y_validation_word_ds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Model for Subword Dataset"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"histroy_subword = model_subword.fit(x=x_train_subword_ds,\n                                    y=y_train_subword_ds,\n                                    batch_size=32,\n                                    epochs=50,\n                                    callbacks=my_callback,\n                                    validation_data=(x_validation_subword_ds, y_validation_subword_ds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check the Training History => Overfitting"},{"metadata":{},"cell_type":"markdown","source":"### Word Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_acc = history_word.history[\"acc\"]\nvalidation_acc = history_word.history[\"val_acc\"]\nepochs = list(range(len(validation_acc)))\n\nplt.plot(epochs, training_acc, color=\"blue\", label=\"Training Acc\")\nplt.plot(epochs, validation_acc, color=\"red\", label=\"Validation Acc\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Subword Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_acc = histroy_subword.history[\"acc\"]\nvalidation_acc = histroy_subword.history[\"val_acc\"]\nepochs = list(range(len(validation_acc)))\n\nplt.plot(epochs, training_acc, color=\"blue\", label=\"Training Acc\")\nplt.plot(epochs, validation_acc, color=\"red\", label=\"Validation Acc\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}