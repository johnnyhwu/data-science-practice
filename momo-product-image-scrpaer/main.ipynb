{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import threading\n",
    "import random\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData():\n",
    "    df = pd.read_excel(\"number.xlsx\")\n",
    "    return df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildURL(main_url, paras):\n",
    "    urls = []\n",
    "    for item in paras:\n",
    "        urls.append(main_url.format(str(item), str(item)))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiThreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiThreading(urls, maximum_thread, target_func):\n",
    "    num_url = 0\n",
    "    num_thread = 0\n",
    "    threads = []\n",
    "    while (num_url < len(urls)):\n",
    "        if num_thread == maximum_thread:\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "            threads.clear()\n",
    "            num_thread = 0\n",
    "\n",
    "        t = threading.Thread(target=target_func, args=[urls[num_url]])\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "        num_thread += 1\n",
    "        num_url += 1\n",
    "        qbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScrapeData(url):\n",
    "    time.sleep(random.randint(3,10))\n",
    "    home_url = \"https://www.momoshop.com.tw\"\n",
    "    \n",
    "    message = url\n",
    "    pattern = re.compile(\"&kw=(\\d)+\")\n",
    "    match = pattern.search(message)\n",
    "    key = match.group()[4:]\n",
    "    \n",
    "    imgs_url = []\n",
    "    \n",
    "    browser = webdriver.Edge(\"C:\\\\edgedriver_win64\\\\msedgedriver.exe\")\n",
    "    \n",
    "    browser.get(url)\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    \n",
    "    # get the top image of product\n",
    "    try:\n",
    "        top_img = soup.find(\"img\", class_=\"jqzoom\")[\"src\"]\n",
    "        imgs_url.append(top_img)\n",
    "    except:\n",
    "        print(\"Failed: Extraction of {}'s top image.\".format(key))\n",
    "        browser.close()\n",
    "        return\n",
    "        \n",
    "    \n",
    "    # get the iframe page\n",
    "    try:\n",
    "        iframe_url = home_url+soup.find(\"iframe\", id=\"ifrmGoods\")[\"src\"]\n",
    "        browser.get(iframe_url)\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    except:\n",
    "        print(\"Failed: Go to {}'s iframe page'\".format(key))\n",
    "        browser.close()\n",
    "        return\n",
    "    \n",
    "    # get the image in iframe page\n",
    "    try:\n",
    "        imgs = soup.find_all(\"img\")\n",
    "        for img in imgs:\n",
    "            imgs_url.append(img[\"src\"])\n",
    "    except:\n",
    "        print(\"Failed: Extraction of {}'s iframe image.\".format(key))\n",
    "        browser.close()\n",
    "        return\n",
    "    \n",
    "    store_data[key] = imgs_url\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code={}&Area=search&mdiv=403&oid=1_1&cid=index&kw={}\"\n",
    "store_data = {}\n",
    "paras = LoadData()\n",
    "urls = BuildURL(main_url, paras)\n",
    "qbar = tqdm(total=len(urls))\n",
    "MultiThreading(urls, 5, ScrapeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6829702\n",
      "5621965\n",
      "2885961\n",
      "2201970\n",
      "3124085\n",
      "1433974\n",
      "997610\n",
      "997608\n",
      "997607\n",
      "944537\n"
     ]
    }
   ],
   "source": [
    "# scrape failed\n",
    "for i in paras:\n",
    "    if str(i) not in store_data.keys():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data frame\n",
    "df = pd.DataFrame.from_dict(store_data, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to excel\n",
    "df.to_excel(\"whai.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
