{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Import Package"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split into Training & Validation Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_ratio = 0.8\nnp.random.shuffle(dataset)\n\ntraining_dataset = dataset[:int(dataset.shape[0] * training_data_ratio), :]\nvalidation_dataset = dataset[int(dataset.shape[0] * training_data_ratio):, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The shape of training dataset: \", training_dataset.shape)\nprint(\"The shape of validation dataset: \", validation_dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenize Sentence & Label for Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a tokenizer\ntokenizer = keras.preprocessing.text.Tokenizer(num_words=12000, oov_token=\"<OOV>\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit tokenizer on training sentences\ntokenizer.fit_on_texts(training_dataset[:, 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the word - value pair\ntokenizer.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenize training sentences and validation sentences\nx_train = tokenizer.texts_to_sequences(training_dataset[:, 0])\nx_validation = tokenizer.texts_to_sequences(validation_dataset[:, 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# length of sequences in training set are different, so are sentences in validation set\nprint(\"The length of sentence in training set: \", len(x_train[0]))\nprint(\"The length of sentence in training set: \", len(x_train[100]))\n\nprint(\"The length of sentence in validation set: \", len(x_validation[0]))\nprint(\"The length of sentence in validation set: \", len(x_validation[100]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pad the sentence to make them same length\nx_train = keras.preprocessing.sequence.pad_sequences(sequences=x_train, \n                                           maxlen=256,\n                                           padding=\"post\",\n                                           truncating=\"post\")\n\nx_validation = keras.preprocessing.sequence.pad_sequences(sequences=x_validation, \n                                                          maxlen=256,\n                                                          padding=\"post\",\n                                                          truncating=\"post\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The length of sentence in training set: \", len(x_train[0]))\nprint(\"The length of sentence in training set: \", len(x_train[100]))\n\nprint(\"The length of sentence in validation set: \", len(x_validation[0]))\nprint(\"The length of sentence in validation set: \", len(x_validation[100]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert training labels and validation labels to one-of-two encoding form\ny_train = training_dataset[: ,1]\ny_validation = validation_dataset[:, 1]\n\nprint(\"Training Labels: \", y_train)\nprint(\"Validation Labels: \", y_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert string two integer\nmask_pos = (y_train == \"positive\")\nmask_neg = (y_train == \"negative\")\ny_train[mask_pos] = 1\ny_train[mask_neg] = 0\n\n\nmask_pos = (y_validation == \"positive\")\nmask_neg = (y_validation == \"negative\")\ny_validation[mask_pos] = 1\ny_validation[mask_neg] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-of-two encoding form\ny_train = keras.utils.to_categorical(y=y_train, num_classes=2)\ny_validation = keras.utils.to_categorical(y=y_validation, num_classes=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# have a look on part on training data\nprint(\"Part of Training Data: \")\nprint()\nprint(\"Sentences: \")\nprint(x_train[0:10])\nprint()\nprint(\"Labels: \")\nprint(y_train[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# have a look on part on validation data\nprint(\"Part of Validation Data: \")\nprint()\nprint(\"Sentences: \")\nprint(x_validation[0:10])\nprint()\nprint(\"Labels: \")\nprint(y_validation[0:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Model"},{"metadata":{},"cell_type":"markdown","source":"### Model Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = keras.layers.Input(shape=(256, ))\nx = keras.layers.Embedding(input_dim=12000, output_dim=48, input_length=256)(inputs)\nx = keras.layers.Flatten()(x)\nx = keras.layers.Dense(units=24, activation=\"relu\")(x)\nx = keras.layers.Dense(units=12, activation=\"relu\")(x)\noutputs = keras.layers.Dense(units=2, activation=\"softmax\")(x)\n\nmodel = keras.models.Model(inputs=inputs, outputs=outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Compilation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomCallback(keras.callbacks.Callback):\n    \n    def on_epoch_end(self, epoch, logs):\n        if logs[\"acc\"] >= 0.99:\n            self.model.stop_training = True\n    \ncustom_callback = CustomCallback()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=x_train,\n          y=y_train,\n          batch_size=32,\n          epochs=20,\n          callbacks=custom_callback,\n          validation_data=(x_validation, y_validation))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Performance of Training Process (Overfitting)"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_acc = history.history[\"acc\"]\nvalidation_acc = history.history[\"val_acc\"]\nepoch = list(range(len(training_acc)))\n\nplt.plot(epoch, training_acc, \"b\", label=\"Training Acc\")\nplt.plot(epoch, validation_acc, \"r\", label=\"Validation Acc\")\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract Embedding Vector"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the embedding layer in model\nembedding_layer = model.layers[1]\n\n# get the weight of embedding layer\nembedding_matrix = embedding_layer.get_weights()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# each row in embedding matrix represents embedding vector of word\nembedding_matrix.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}