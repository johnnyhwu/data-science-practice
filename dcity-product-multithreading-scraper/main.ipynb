{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import queue\n",
    "import threading\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Job Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_dict = {\n",
    "    \"japan_refrigerator\": \"https://www.dcity.com.tw/Large/1904020047/?P=1\",\n",
    "    \"refrigerator\": \"https://www.dcity.com.tw/Large/1904020048/?P=1\",\n",
    "    \"freezer\": \"https://www.dcity.com.tw/Large/1904020049/?P=1\",\n",
    "    \"upright_washing_machine\": \"https://www.dcity.com.tw/Large/1904020050/?P=1\",\n",
    "    \"drum_washing_machine\": \"https://www.dcity.com.tw/Large/1904020051/?P=1\",\n",
    "    \"cloth_dryer\": \"https://www.dcity.com.tw/Large/1904020052/?P=1\",\n",
    "    \"vacuum\": \"https://www.dcity.com.tw/Life/1904020020/?P=1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_queue = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in base_url_dict.items():\n",
    "    job_queue.put(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Worker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(threading.Thread):\n",
    "    \n",
    "    def __init__(self, job_queue):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.key = None\n",
    "        self.url = None\n",
    "        self.webdriver = None\n",
    "        \n",
    "        self.job_queue = job_queue\n",
    "        \n",
    "    \n",
    "    def init_list(self):\n",
    "        self.final_dict = {}\n",
    "        self.product_url_list = []\n",
    "        self.product_name_list = []\n",
    "        self.product_price_list = []\n",
    "        self.product_info_list = []\n",
    "        self.product_id_list = []\n",
    "        self.product_img_list = []\n",
    "        \n",
    "    def run(self):\n",
    "        while self.job_queue.empty() is False:\n",
    "            \n",
    "            self.init_list()\n",
    "            \n",
    "            self.key, self.url = self.get_job()\n",
    "            \n",
    "            self.activate_webdriver()\n",
    "            \n",
    "            self.scrape_data()\n",
    "            \n",
    "            self.deactivate_webdriver()\n",
    "            \n",
    "    def get_job(self):\n",
    "        job = self.job_queue.get()\n",
    "        return job[0], job[1]\n",
    "    \n",
    "    def activate_webdriver(self):\n",
    "        self.webdriver = webdriver.Chrome(\"C:\\chromedriver_win32\\chromedriver\")\n",
    "        \n",
    "    def deactivate_webdriver(self):\n",
    "        self.webdriver.close()\n",
    "        \n",
    "    def scrape_data(self):\n",
    "        \n",
    "        current_page_num = 0\n",
    "        total_product_num = self.get_total_product_num()\n",
    "        \n",
    "        if total_product_num is None:\n",
    "            return\n",
    "        \n",
    "        while len(self.product_url_list) < total_product_num:\n",
    "            \n",
    "            current_page_num += 1\n",
    "            self.url = self.url[:-1] + str(current_page_num)\n",
    "            \n",
    "            success = self.get_all_product_url()\n",
    "            \n",
    "            if success is False:\n",
    "                return\n",
    "            \n",
    "        self.scrape_each_product()\n",
    "        \n",
    "        self.build_final_dict()\n",
    "        \n",
    "        self.save_dict_to_pickle()\n",
    "        \n",
    "        self.convert_dict_to_df_to_excel()\n",
    "            \n",
    "            \n",
    "            \n",
    "    def get_total_product_num(self):\n",
    "        print(self.url)\n",
    "        self.webdriver.get(self.url)\n",
    "        time.sleep(3)\n",
    "        html = self.webdriver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        try:\n",
    "            result = int(soup.find(\"span\", class_=\"btn-group page\").find_all(\"b\")[1].text)\n",
    "        except:\n",
    "            print(\"{} cannot get total product num\".format(self.key))\n",
    "            result = None\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def get_all_product_url(self):\n",
    "        self.webdriver.get(self.url)\n",
    "        time.sleep(3)\n",
    "        html = self.webdriver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        try:\n",
    "            for product in soup.find_all(\"div\", class_=\"col-xs-6 col-md-4 col-lg-3\"):\n",
    "                self.product_url_list.append(\"https://www.dcity.com.tw\" + product.find(\"a\")[\"href\"])\n",
    "            return True\n",
    "        except:\n",
    "            print(\"{} cannot get all product url\".format(self.key))\n",
    "            return False\n",
    "            \n",
    "            \n",
    "    def scrape_each_product(self):\n",
    "        \n",
    "        print(\"Worker's Key: {}\".format(self.key))\n",
    "        for idx in tqdm(range(len(self.product_url_list))):\n",
    "            \n",
    "            self.webdriver.get(self.product_url_list[idx])\n",
    "            time.sleep(3)\n",
    "            html = self.webdriver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            # name\n",
    "            try:\n",
    "                name = soup.find(\"h1\", itemprop=\"name\").text\n",
    "            except:\n",
    "                name = \"Fail: {}\".format(self.product_url_list[idx])\n",
    "            \n",
    "            self.product_name_list.append(name)\n",
    "            \n",
    "            \n",
    "            # price\n",
    "            try:\n",
    "                price = soup.find(\"span\", class_=\"price\").text.split(\"\\n\")\n",
    "            except:\n",
    "                price = \"Fail: {}\".format(self.product_url_list[idx])\n",
    "                \n",
    "            self.product_price_list.append(price)\n",
    "            \n",
    "            \n",
    "            # id\n",
    "            try:\n",
    "                _id = soup.find(\"div\", class_=\"pro-code\").find(\"span\").text\n",
    "            except:\n",
    "                _id = \"Fail: {}\".format(self.product_url_list[idx])\n",
    "            \n",
    "            self.product_id_list.append(_id)\n",
    "            \n",
    "            \n",
    "            # img\n",
    "            try:\n",
    "                img = \"https://www.dcity.com.tw\" + soup.find(\"img\", itemprop=\"image\")[\"src\"]\n",
    "            except:\n",
    "                img = \"Fail: {}\".format(self.product_url_list[idx])\n",
    "                \n",
    "            self.product_img_list.append(img)\n",
    "            \n",
    "            \n",
    "            # info\n",
    "            try:\n",
    "                top_info = soup.find(\"h2\", class_=\"description\", itemprop=\"description\").text.strip()\n",
    "            except:\n",
    "                top_info = \"Fail: {}\".format(self.product_url_list[idx])\n",
    "                \n",
    "            try:\n",
    "                bottom_info_list = soup.find(\"div\", id=\"proList-1\").text.strip().split()\n",
    "                \n",
    "                a = bottom_info_list.index(\"規格說明\")\n",
    "                bottom_info_list = bottom_info_list[a:]\n",
    "                \n",
    "                bottom_info = \"\"\n",
    "                for string in bottom_info_list:\n",
    "                    bottom_info += (\"\\n\" + string)\n",
    "            except:\n",
    "                bottom_info = \"Fail: {}\".format(self.product_url_list[idx])\n",
    "                \n",
    "            info = top_info + \"\\n\" + \"\\n\" + bottom_info\n",
    "            self.product_info_list.append(info)\n",
    "            \n",
    "    \n",
    "    def build_final_dict(self):\n",
    "        self.final_dict[\"品名\"] = self.product_name_list\n",
    "        self.final_dict[\"價格\"] = self.product_price_list\n",
    "        self.final_dict[\"詳情\"] = self.product_info_list\n",
    "        self.final_dict[\"貨號\"] = self.product_id_list\n",
    "        self.final_dict[\"圖片\"] = self.product_img_list\n",
    "        \n",
    "    \n",
    "    def save_dict_to_pickle(self):\n",
    "        with open(self.key, \"wb\") as file:\n",
    "            pickle.dump(self.final_dict, file)\n",
    "            \n",
    "    def convert_dict_to_df_to_excel(self):\n",
    "        df = pd.DataFrame.from_dict(self.final_dict)\n",
    "        df.to_excel(\"{}.xlsx\".format(self.key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dcity.com.tw/Large/1904020047/?P=1\n",
      "https://www.dcity.com.tw/Large/1904020049/?P=1\n",
      "https://www.dcity.com.tw/Large/1904020048/?P=1\n",
      "Worker's Key: freezer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programming\\pythondev\\application\\scrapedcity\\venv\\lib\\site-packages\\ipykernel_launcher.py:107: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa7d7e493f743998bd79ed8040acfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker's Key: japan_refrigerator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3503893f8f44ad49a47de515e25c850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=47.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker's Key: refrigerator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1651e60ccde41ed87dbb6976404a012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=145.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://www.dcity.com.tw/Large/1904020050/?P=1\n",
      "Worker's Key: upright_washing_machine\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce173e942b4436ea5f5577be4807db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://www.dcity.com.tw/Large/1904020051/?P=1\n",
      "Worker's Key: drum_washing_machine\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07696588f76e408b9f55437f8d6ace45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://www.dcity.com.tw/Large/1904020052/?P=1\n",
      "Worker's Key: cloth_dryer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0b62aca9c44b128afb049ff8e76ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://www.dcity.com.tw/Life/1904020020/?P=1\n",
      "Worker's Key: vacuum\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955ec6e899c9431c8a8a5632fe1cc6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "worker1 = Worker(job_queue)\n",
    "worker2 = Worker(job_queue)\n",
    "worker3 = Worker(job_queue)\n",
    "worker1.start()\n",
    "worker2.start()\n",
    "worker3.start()\n",
    "worker1.join()\n",
    "worker2.join()\n",
    "worker3.join()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
